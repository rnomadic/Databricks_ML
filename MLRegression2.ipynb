{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPV/Bvw/gRt1jQziPzGyyZ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rnomadic/Databricks_ML/blob/main/MLRegression2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMdqNizPv8kk"
      },
      "outputs": [],
      "source": [
        "## Github File Name \"MLRegression2\"\n",
        "## When saving this file in Github please change the existing filename, it will overwrite\n",
        "\n",
        "## One hot encoder\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
        "\n",
        "categorical_cols = [field for (field, dataType) in train_df.dtypes if dataType == \"string\"]\n",
        "index_output_cols = [x + \"Index\" for x in categorical_cols]\n",
        "ohe_output_cols = [x + \"OHE\" for x in categorical_cols]\n",
        "\n",
        "string_indexer = StringIndexer(inputCols=categorical_cols, outputCols=index_output_cols, handleInvalid=\"skip\")\n",
        "ohe_encoder = OneHotEncoder(inputCols=index_output_cols, outputCols=ohe_output_cols)\n",
        "\n",
        "## Vector Assembler\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "numeric_cols = [field for (field, dataType) in train_df.dtypes if ((dataType == \"double\") & (field != \"price\"))]\n",
        "assembler_inputs = ohe_output_cols + numeric_cols\n",
        "vec_assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
        "\n",
        "## Linear regression\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "lr = LinearRegression(labelCol=\"price\", featuresCol=\"features\")\n",
        "\n",
        "## Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "stages = [string_indexer, ohe_encoder, vec_assembler, lr]\n",
        "pipeline = Pipeline(stages=stages)\n",
        "\n",
        "pipeline_model = pipeline.fit(train_df)\n",
        "\n",
        "## Saving the model\n",
        "pipeline_model.write().overwrite().save(working_dir)\n",
        "\n",
        "## Loading the model\n",
        "from pyspark.ml import PipelineModel\n",
        "\n",
        "saved_pipeline_model = PipelineModel.load(working_dir)\n",
        "\n",
        "## Apply model to test data\n",
        "pred_df = saved_pipeline_model.transform(test_df)\n",
        "\n",
        "display(pred_df.select(\"features\", \"price\", \"prediction\"))\n",
        "\n",
        "## Evaluate Model\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "regression_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"price\", metricName=\"rmse\")\n",
        "\n",
        "rmse = regression_evaluator.evaluate(pred_df)\n",
        "r2 = regression_evaluator.setMetricName(\"r2\").evaluate(pred_df)\n",
        "print(f\"RMSE is {rmse}\")\n",
        "print(f\"R2 is {r2}\")\n",
        "\n",
        "## Linear Regression II Lab\n",
        "\n",
        "## RFormula\n",
        "\"\"\"\n",
        "Instead of manually specifying which columns are categorical to the StringIndexer and OneHotEncoder, \n",
        "RFormula can do that automatically. With RFormula, if you have any columns of type String, \n",
        "it treats it as a categorical feature and string indexes & one hot encodes it for us. Otherwise, it leaves as it is. \n",
        "Then it combines all of one-hot encoded features and numeric features into a single vector, called features.\n",
        "\"\"\"\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import RFormula\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "r_formula = RFormula(\n",
        "    formula=\"price ~ .\", # want to take all the features\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"label\")\n",
        "\n",
        "lr = LinearRegression(labelCol=\"price\", featuresCol=\"features\")\n",
        "stages = [r_formula, lr]\n",
        "pipeline = Pipeline(stages=stages)\n",
        "pipeline_model = pipeline.fit(train_df)\n",
        "pred_df = pipeline_model.transform(test_df)\n",
        "regression_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"price\", metricName=\"rmse\")\n",
        "#regression_evaluator = RegressionEvaluator(<FILL_IN>)\n",
        "\n",
        "rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(pred_df)\n",
        "r2 = regression_evaluator.setMetricName(\"r2\").evaluate(pred_df)\n",
        "print(f\"RMSE is {rmse}\")\n",
        "print(f\"R2 is {r2}\")\n",
        "\n",
        "\n",
        "## Log Scale\n",
        "\"\"\"\n",
        "Now that we have verified we get the same result using RFormula as above, \n",
        "we are going to improve upon our model. If you recall, our price dependent \n",
        "variable appears to be log-normally distributed, so we are going to try to predict it on the log scale.\n",
        "Let's convert our price to be on log scale, and have the linear regression model predict the log price\n",
        "\"\"\"\n",
        "\n",
        "from pyspark.sql.functions import log\n",
        "display(train_df.select(log(\"price\")))\n",
        "\n",
        "## Linear regression model predict the log price\n",
        "from pyspark.sql.functions import col, log\n",
        "\n",
        "log_train_df = train_df.withColumn(\"log_price\", log(col(\"price\")))\n",
        "log_test_df = test_df.withColumn(\"log_price\", log(col(\"price\")))\n",
        "r_formula = RFormula(formula=\"log_price ~ . - price\", featuresCol=\"features\", labelCol=\"log_price\", handleInvalid=\"skip\")\n",
        "lr.setLabelCol(\"log_price\").setPredictionCol(\"log_pred\")\n",
        "pipeline = Pipeline(stages=[r_formula, lr])\n",
        "pipeline_model = pipeline.fit(log_train_df)\n",
        "pred_df = pipeline_model.transform(log_test_df)\n",
        "\n",
        "## Exponentiate\n",
        "## In order to interpret our RMSE, we need to convert our predictions back from logarithmic scale.\n",
        "from pyspark.sql.functions import col, exp\n",
        "\n",
        "exp_df = pred_df.withColumn(\"prediction\", exp(col(\"log_pred\"))) ## See we change from log to exponentials\n",
        "\n",
        "rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(exp_df)\n",
        "r2 = regression_evaluator.setMetricName(\"r2\").evaluate(exp_df)\n",
        "print(f\"RMSE is {rmse}\")\n",
        "print(f\"R2 is {r2}\")"
      ]
    }
  ]
}