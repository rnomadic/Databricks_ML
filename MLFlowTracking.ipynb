{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCAblDmvi/muHcENOhtyxT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rnomadic/Databricks_ML/blob/main/MLFlowTracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMdqNizPv8kk"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Each run can record the following information:\n",
        "\n",
        "Parameters: Key-value pairs of input parameters such as the number of trees in a random forest model\n",
        "Metrics: Evaluation metrics such as RMSE or Area Under the ROC Curve\n",
        "Artifacts: Arbitrary output files in any format. This can include images, pickled models, and data files\n",
        "Source: The code that originally ran the experiment\n",
        "NOTE: For Spark models, MLflow can only log PipelineModels.\n",
        "\"\"\"\n",
        "import mlflow\n",
        "import mlflow.spark\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "with mlflow.start_run(run_name=\"LR-Single-Feature\") as run:\n",
        "    # Define pipeline\n",
        "    vec_assembler = VectorAssembler(inputCols=[\"bedrooms\"], outputCol=\"features\")\n",
        "    lr = LinearRegression(featuresCol=\"features\", labelCol=\"price\")\n",
        "    pipeline = Pipeline(stages=[vec_assembler, lr])\n",
        "    pipeline_model = pipeline.fit(train_df)\n",
        "\n",
        "    # Log parameters\n",
        "    mlflow.log_param(\"label\", \"price\")\n",
        "    mlflow.log_param(\"features\", \"bedrooms\")\n",
        "\n",
        "    # Log model\n",
        "    mlflow.spark.log_model(pipeline_model, \"model\", input_example=train_df.limit(5).toPandas()) \n",
        "\n",
        "    # Evaluate predictions\n",
        "    pred_df = pipeline_model.transform(test_df)\n",
        "    regression_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"price\", metricName=\"rmse\")\n",
        "    rmse = regression_evaluator.evaluate(pred_df)\n",
        "\n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"rmse\", rmse)\n",
        "\n",
        "    ## Next let's build our linear regression model but use all of our features.\n",
        "\n",
        "from pyspark.ml.feature import RFormula\n",
        "\n",
        "with mlflow.start_run(run_name=\"LR-All-Features\") as run:\n",
        "    # Create pipeline\n",
        "    r_formula = RFormula(formula=\"price ~ .\", featuresCol=\"features\", labelCol=\"price\", handleInvalid=\"skip\")\n",
        "    lr = LinearRegression(labelCol=\"price\", featuresCol=\"features\")\n",
        "    pipeline = Pipeline(stages=[r_formula, lr])\n",
        "    pipeline_model = pipeline.fit(train_df)\n",
        "\n",
        "    # Log pipeline\n",
        "    mlflow.spark.log_model(pipeline_model, \"model\", input_example=train_df.limit(5).toPandas())\n",
        "\n",
        "    # Log parameter\n",
        "    mlflow.log_param(\"label\", \"price\")\n",
        "    mlflow.log_param(\"features\", \"all_features\")\n",
        "\n",
        "    # Create predictions and metrics\n",
        "    pred_df = pipeline_model.transform(test_df)\n",
        "    regression_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")\n",
        "    rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(pred_df)\n",
        "    r2 = regression_evaluator.setMetricName(\"r2\").evaluate(pred_df)\n",
        "\n",
        "    # Log both metrics\n",
        "    mlflow.log_metric(\"rmse\", rmse)\n",
        "    mlflow.log_metric(\"r2\", r2)\n",
        "\"\"\"\n",
        "Finally, we will use Linear Regression to predict the log of the price, due to its log normal distribution.\n",
        "We'll also practice logging artifacts to keep a visual of our log normal histogram.\n",
        "\"\"\"\n",
        "\n",
        "from pyspark.sql.functions import col, log, exp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with mlflow.start_run(run_name=\"LR-Log-Price\") as run:\n",
        "    # Take log of price\n",
        "    log_train_df = train_df.withColumn(\"log_price\", log(col(\"price\")))\n",
        "    log_test_df = test_df.withColumn(\"log_price\", log(col(\"price\")))\n",
        "\n",
        "    # Log parameter\n",
        "    mlflow.log_param(\"label\", \"log_price\")\n",
        "    mlflow.log_param(\"features\", \"all_features\")\n",
        "\n",
        "    # Create pipeline\n",
        "    r_formula = RFormula(formula=\"log_price ~ . - price\", featuresCol=\"features\", labelCol=\"log_price\", handleInvalid=\"skip\")  \n",
        "    lr = LinearRegression(labelCol=\"log_price\", predictionCol=\"log_prediction\")\n",
        "    pipeline = Pipeline(stages=[r_formula, lr])\n",
        "    pipeline_model = pipeline.fit(log_train_df)\n",
        "\n",
        "    # Log model\n",
        "    mlflow.spark.log_model(pipeline_model, \"log-model\", input_example=log_train_df.limit(5).toPandas())\n",
        "\n",
        "    # Make predictions\n",
        "    pred_df = pipeline_model.transform(log_test_df)\n",
        "    exp_df = pred_df.withColumn(\"prediction\", exp(col(\"log_prediction\")))\n",
        "\n",
        "    # Evaluate predictions\n",
        "    rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(exp_df)\n",
        "    r2 = regression_evaluator.setMetricName(\"r2\").evaluate(exp_df)\n",
        "\n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"rmse\", rmse)\n",
        "    mlflow.log_metric(\"r2\", r2)\n",
        "\n",
        "    # Log artifact\n",
        "    plt.clf()\n",
        "\n",
        "    log_train_df.toPandas().hist(column=\"log_price\", bins=100)\n",
        "    fig = plt.gcf()\n",
        "    mlflow.log_figure(fig, username + \"_log_normal.png\")\n",
        "    plt.show()\n",
        "\"\"\"\n",
        "Querying Past Runs\n",
        "\"\"\"\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "client = MlflowClient()\n",
        "client.list_experiments()\n",
        "\n",
        "experiment_id = run.info.experiment_id\n",
        "runs_df = mlflow.search_runs(experiment_id)\n",
        "\n",
        "display(runs_df)\n",
        "\n",
        "runs = client.search_runs(experiment_id, order_by=[\"attributes.start_time desc\"], max_results=1)\n",
        "runs[0].data.metrics\n",
        "\n",
        "runs[0].info.run_id\n",
        "\n",
        "\"\"\"\n",
        "Examine the results in the UI. Look for the following:\n",
        "\n",
        "\n",
        "The Experiment ID\n",
        "The artifact location. This is where the artifacts are stored in DBFS.\n",
        "The time the run was executed. Click this to see more information on the run.\n",
        "The code that executed the run.\n",
        "After clicking on the time of the run, take a look at the following:\n",
        "\n",
        "\n",
        "The Run ID will match what we printed above\n",
        "The model that we saved, included a pickled version of the model as well as the Conda environment and the MLmodel file.\n",
        "\"\"\"\n",
        "\n",
        "## Load saved model\n",
        "model_path = f\"runs:/{run.info.run_id}/log-model\"\n",
        "loaded_model = mlflow.spark.load_model(model_path)\n",
        "\n",
        "display(loaded_model.transform(test_df))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## MLFlow Lab\n",
        "\n"
      ]
    }
  ]
}