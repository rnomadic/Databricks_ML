{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOgL4emN+/2m7r7rR0ZEOja",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rnomadic/Databricks_ML/blob/main/MLFlowTracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMdqNizPv8kk"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Each run can record the following information:\n",
        "\n",
        "Parameters: Key-value pairs of input parameters such as the number of trees in a random forest model\n",
        "Metrics: Evaluation metrics such as RMSE or Area Under the ROC Curve\n",
        "Artifacts: Arbitrary output files in any format. This can include images, pickled models, and data files\n",
        "Source: The code that originally ran the experiment\n",
        "NOTE: For Spark models, MLflow can only log PipelineModels.\n",
        "\"\"\"\n",
        "import mlflow\n",
        "import mlflow.spark\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "with mlflow.start_run(run_name=\"LR-Single-Feature\") as run:\n",
        "    # Define pipeline\n",
        "    vec_assembler = VectorAssembler(inputCols=[\"bedrooms\"], outputCol=\"features\")\n",
        "    lr = LinearRegression(featuresCol=\"features\", labelCol=\"price\")\n",
        "    pipeline = Pipeline(stages=[vec_assembler, lr])\n",
        "    pipeline_model = pipeline.fit(train_df)\n",
        "\n",
        "    # Log parameters\n",
        "    mlflow.log_param(\"label\", \"price\")\n",
        "    mlflow.log_param(\"features\", \"bedrooms\")\n",
        "\n",
        "    # Log model\n",
        "    mlflow.spark.log_model(pipeline_model, \"model\", input_example=train_df.limit(5).toPandas()) \n",
        "\n",
        "    # Evaluate predictions\n",
        "    pred_df = pipeline_model.transform(test_df)\n",
        "    regression_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"price\", metricName=\"rmse\")\n",
        "    rmse = regression_evaluator.evaluate(pred_df)\n",
        "\n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"rmse\", rmse)\n",
        "\n",
        "    ## Next let's build our linear regression model but use all of our features.\n",
        "\n",
        "from pyspark.ml.feature import RFormula\n",
        "\n",
        "with mlflow.start_run(run_name=\"LR-All-Features\") as run:\n",
        "    # Create pipeline\n",
        "    r_formula = RFormula(formula=\"price ~ .\", featuresCol=\"features\", labelCol=\"price\", handleInvalid=\"skip\")\n",
        "    lr = LinearRegression(labelCol=\"price\", featuresCol=\"features\")\n",
        "    pipeline = Pipeline(stages=[r_formula, lr])\n",
        "    pipeline_model = pipeline.fit(train_df)\n",
        "\n",
        "    # Log pipeline\n",
        "    mlflow.spark.log_model(pipeline_model, \"model\", input_example=train_df.limit(5).toPandas())\n",
        "\n",
        "    # Log parameter\n",
        "    mlflow.log_param(\"label\", \"price\")\n",
        "    mlflow.log_param(\"features\", \"all_features\")\n",
        "\n",
        "    # Create predictions and metrics\n",
        "    pred_df = pipeline_model.transform(test_df)\n",
        "    regression_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")\n",
        "    rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(pred_df)\n",
        "    r2 = regression_evaluator.setMetricName(\"r2\").evaluate(pred_df)\n",
        "\n",
        "    # Log both metrics\n",
        "    mlflow.log_metric(\"rmse\", rmse)\n",
        "    mlflow.log_metric(\"r2\", r2)\n",
        "\"\"\"\n",
        "Finally, we will use Linear Regression to predict the log of the price, due to its log normal distribution.\n",
        "We'll also practice logging artifacts to keep a visual of our log normal histogram.\n",
        "\"\"\"\n",
        "\n",
        "from pyspark.sql.functions import col, log, exp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with mlflow.start_run(run_name=\"LR-Log-Price\") as run:\n",
        "    # Take log of price\n",
        "    log_train_df = train_df.withColumn(\"log_price\", log(col(\"price\")))\n",
        "    log_test_df = test_df.withColumn(\"log_price\", log(col(\"price\")))\n",
        "\n",
        "    # Log parameter\n",
        "    mlflow.log_param(\"label\", \"log_price\")\n",
        "    mlflow.log_param(\"features\", \"all_features\")\n",
        "\n",
        "    # Create pipeline\n",
        "    r_formula = RFormula(formula=\"log_price ~ . - price\", featuresCol=\"features\", labelCol=\"log_price\", handleInvalid=\"skip\")  \n",
        "    lr = LinearRegression(labelCol=\"log_price\", predictionCol=\"log_prediction\")\n",
        "    pipeline = Pipeline(stages=[r_formula, lr])\n",
        "    pipeline_model = pipeline.fit(log_train_df)\n",
        "\n",
        "    # Log model\n",
        "    mlflow.spark.log_model(pipeline_model, \"log-model\", input_example=log_train_df.limit(5).toPandas())\n",
        "\n",
        "    # Make predictions\n",
        "    pred_df = pipeline_model.transform(log_test_df)\n",
        "    exp_df = pred_df.withColumn(\"prediction\", exp(col(\"log_prediction\")))\n",
        "\n",
        "    # Evaluate predictions\n",
        "    rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(exp_df)\n",
        "    r2 = regression_evaluator.setMetricName(\"r2\").evaluate(exp_df)\n",
        "\n",
        "    # Log metrics\n",
        "    mlflow.log_metric(\"rmse\", rmse)\n",
        "    mlflow.log_metric(\"r2\", r2)\n",
        "\n",
        "    # Log artifact\n",
        "    plt.clf()\n",
        "\n",
        "    log_train_df.toPandas().hist(column=\"log_price\", bins=100)\n",
        "    fig = plt.gcf()\n",
        "    mlflow.log_figure(fig, username + \"_log_normal.png\")\n",
        "    plt.show()\n",
        "\"\"\"\n",
        "Querying Past Runs\n",
        "\"\"\"\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "client = MlflowClient()\n",
        "client.list_experiments()\n",
        "\n",
        "experiment_id = run.info.experiment_id\n",
        "runs_df = mlflow.search_runs(experiment_id)\n",
        "\n",
        "display(runs_df)\n",
        "\n",
        "runs = client.search_runs(experiment_id, order_by=[\"attributes.start_time desc\"], max_results=1)\n",
        "runs[0].data.metrics\n",
        "\n",
        "runs[0].info.run_id\n",
        "\n",
        "\"\"\"\n",
        "Examine the results in the UI. Look for the following:\n",
        "\n",
        "\n",
        "The Experiment ID\n",
        "The artifact location. This is where the artifacts are stored in DBFS.\n",
        "The time the run was executed. Click this to see more information on the run.\n",
        "The code that executed the run.\n",
        "After clicking on the time of the run, take a look at the following:\n",
        "\n",
        "\n",
        "The Run ID will match what we printed above\n",
        "The model that we saved, included a pickled version of the model as well as the Conda environment and the MLmodel file.\n",
        "\"\"\"\n",
        "\n",
        "## Load saved model\n",
        "model_path = f\"runs:/{run.info.run_id}/log-model\"\n",
        "loaded_model = mlflow.spark.load_model(model_path)\n",
        "\n",
        "display(loaded_model.transform(test_df))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## MLFlow Lab --------------------------------------------------------\n",
        "\"\"\"\n",
        "Step 2. Log initial run to MLflow\n",
        "\"\"\"\n",
        "\n",
        "import mlflow\n",
        "import mlflow.spark\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.feature import RFormula\n",
        "\n",
        "with mlflow.start_run(run_name=\"lr_model\") as run:\n",
        "      #log parameter\n",
        "      mlflow.log_param(\"label\", \"price_all_features\")\n",
        "      mlflow.log_param(\"data_version\", data_version)\n",
        "      mlflow.log_param(\"data_path\", train_delta_path)\n",
        "\n",
        "      ##create pipeline\n",
        "      r_formula = RFormula(formula=\"price ~ .\", featuresCol=\"features\", labelCol=\"price\", handleInvalid=\"skip\")\n",
        "      lr = LinearRegression(labelCol=\"price\", featuresCol=\"features\")\n",
        "      stages =[r_formula, lr]\n",
        "      pipeline = Pipeline(stages=stages)\n",
        "      model = pipeline.fit(train_delta)\n",
        "\n",
        "      #log pipeline\n",
        "      #remember NOTE: For Spark models, MLflow can only log PipelineModels.\n",
        "      mlflow.spark.log_model(model, \"model\")\n",
        "\n",
        "      #create prediction and metrics\n",
        "      pred_df = model.transform(test_delta)\n",
        "      regression_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")\n",
        "      rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(pred_df)\n",
        "      r2 = regression_evaluator.setMetricName(\"r2\").evaluate(pred_df)\n",
        "\n",
        "      #log metric\n",
        "      mlflow.log_metric(\"rmse\", rmse)\n",
        "      mlflow.log_metric(\"r2\", r2)\n",
        "\n",
        "      run_id = run.info.run_id\n",
        "\n",
        "      \"\"\"\n",
        "      Step 3. Register model and move to staging using MLflow Model Registry \n",
        "      We are happy with the performance of the above model and want to move it to \n",
        "      staging. Let's create the model and register it to the MLflow model registry.\n",
        "      \"\"\"\n",
        "\n",
        "      model_name = f\"{cleaned_username}_mllib_lr\"\n",
        "      model_uri = f\"runs:/{run_id}/model\"\n",
        "      model_detail = mlflow.register_model(model_uri=model_uri, name=model_name)\n",
        "\n",
        "      #Transition model to staging.\n",
        "      from mlflow.tracking.client import MlflowClient\n",
        "      client = MlflowClient()\n",
        "\n",
        "      client.transition_model_version_stage(name=model_name, \n",
        "                                            version=1, \n",
        "                                            stage=\"staging\")\n",
        "      \n",
        "      # Define a utility method to wait until the model is ready\n",
        "      def wait_for_model(model_name, version, stage=None, status=\"Ready\", timeout=300):\n",
        "          \n",
        "          import time\n",
        "          last_stage= \"unknown\"\n",
        "          last_status= \"unknown\"\n",
        "\n",
        "          for i in range(timeout):\n",
        "              model_version_detail = client.get_model_version(name=model_name, version=version)\n",
        "              last_stage = str(model_version_detail.current_stage)\n",
        "              last_status = str(model_version_detail.status)\n",
        "              if last_status == status & last_stage==str(stage):\n",
        "                return\n",
        "\n",
        "              time.sleep(1)\n",
        "\n",
        "          raise Exception(f\"The model {model_name} version {version} was not {status} after {timeout} seconds\")\n",
        "\n",
        "      #Force our notebook to block until the model is ready\n",
        "      wait_for_model(model_name, 1, stage=\"Staging\")\n",
        "\n",
        "      #Add a model description\n",
        "      client.update_registered_model(name=model_version_detail.name,\n",
        "                                     description=\"This model forecasts Airbnb housing list prices based on various listing inputs.\")\n",
        "\n",
        "\"\"\"\n",
        "Step 4. Feature Engineering: Evolve Data Schema\n",
        "We now want to do some feature engineering with the aim of improving model performance; \n",
        "we can use Delta Lake to track older versions of the dataset.\n",
        "\n",
        "We will add log_price as a new column and update our Delta table with it.\n",
        "\"\"\"\n",
        "\n",
        "from pyspark.sql.functions import col, log, exp\n",
        "# Create a new log_price column for both train and test datasets\n",
        "train_new = train_delta.withColumn(\"log_price\", log(col(\"price\")))\n",
        "test_new = test_delta.withColumn(\"log_price\", log(col(\"price\")))\n",
        "\n",
        "#Save the updated DataFrames to train_delta_path and test_delta_path, respectively, \n",
        "#passing the mergeSchema option to safely evolve its schema.\n",
        "train_new.write.option(\"mergeSchema\", \"true\").format(\"delta\").mode(\"overwrite\").save(train_delta_path)\n",
        "test_new.write.option(\"mergeSchema\", \"true\").format(\"delta\").mode(\"overwrite\").save(test_delta_path)\n",
        "\n",
        "#Look at the difference between the original & modified schemas\n",
        "set(train_delta.schema.fields) ^ set(train_new.schema.fields)\n",
        "\n",
        "#Let's review the Delta history of our train_delta table and load in the most \n",
        "#recent versions of our train and test Delta tables.\n",
        "display(spark.sql(f\"Describe History Delta. {train_delta_path}\"))\n",
        "\n",
        "data_version=1\n",
        "train_delta_new =  spark.read.format(\"delta\").option(\"versionAsOf\", data_version).load(train_delta_path)\n",
        "test_delta_new = spark.read.format(\"delta\").option(\"versionAsOf\", data_version).load(test_delta_path)\n",
        "\n",
        "\"\"\"\n",
        "Step 5. Use log_price as target and track run with MLflow\n",
        "Retrain the model on the updated data and compare its performance \n",
        "to the original, logging results to MLflow.\n",
        "\"\"\"\n",
        "with mlflow.start_run(run_name = \"lr_log_model\") as run:\n",
        "\n",
        "    #log param\n",
        "    mlflow.log_param(\"label\", \"log-price\")\n",
        "    mlflow.log_param(\"data_version\", data_version)\n",
        "    mlflow.log_param(\"data_path\", train_delta_path)\n",
        "\n",
        "    #create pipeline\n",
        "    r_formula = RFormula(formula=\"log_price ~ .-price\", \n",
        "                         featuresCol=\"features\", \n",
        "                         labelCol=\"log_price\", \n",
        "                         handleInvalid=\"skip\")\n",
        "    \n",
        "    lr = LinearRegression(labelCol=\"log_price\", predictionCol=\"log_prediction\")\n",
        "    stages = [r_formula, lr]\n",
        "    pipeline = Pipeline(stages = stages)\n",
        "    pipeline_model = pipeline.fit(train_delta_new)\n",
        "\n",
        "    # Log model and update the registered model\n",
        "    # mlflow.spark.log_model(model, \"model\")\n",
        "    mlflow.spark.log_model(spark_model=pipeline_model, \n",
        "                           artifact_path=\"log-model\", \n",
        "                           registered_model_name=model_name)\n",
        "    \n",
        "    # Create predictions and metrics\n",
        "    pred_df = pipeline_model.transform(test_delta)\n",
        "    exp_df = pred_df.withColumn(\"prediction\", exp(col(\"log_prediction\")))\n",
        "    rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(pred_df)\n",
        "    r2 = regression_evaluator.setMetricName(\"r2\").evaluate(pred_df)t\n",
        "\n",
        "    #log metric\n",
        "    mlflow.log_metric(\"rmse\", rmse)\n",
        "    mlflow.log_metric(\"r2\", r2)\n",
        "\n",
        "    run_id = run.info.run_id\n",
        "\n",
        "    \"\"\"\n",
        "    Step 6. Compare performance across runs by looking at Delta table versions\n",
        "\n",
        "    Use MLflow's mlflow.search_runs API to identify runs according to the version \n",
        "    of data the run was trained on. Let's compare our runs according to our data versions.\n",
        "\n",
        "    Filter based on params.data_path and params.data_version.\n",
        "\n",
        "    And compare which data_version produced best models\n",
        "    \"\"\"\n",
        "    data_version=0\n",
        "    mlflow.search_runs(filter_string=f\"params.data_path= '{train_delta_path}' and params.data_version='{data_version}'\")\n",
        "\n",
        "    data_version=1\n",
        "    mlflow.search_runs(filter_string=f\"params.data_path= '{train_delta_path}' and params.data_version='{data_version}'\")\n",
        "\n",
        "    \"\"\"\n",
        "    Step 7. Move best performing model to production using MLflow model registry\n",
        "    \"\"\"\n",
        "\n",
        "    model_version_infos = clients.search_model_versions(f\"name= '{model_name}'\")\n",
        "    new_model_version = max([model_version_info.version for model_version_info in model_version_infos])\n",
        "\n",
        "    client.update_model_version(name=model_name,\n",
        "                                version= new_model_version,\n",
        "              description=\"This model version was built using a MLlib Linear \\\n",
        "              Regression model with all features and log_price as predictor.\"\n",
        "                                )\n",
        "    \n"
      ]
    }
  ]
}